{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge de Ingenier√≠a de Datos - Twitter Farmers Protest\n",
    "\n",
    "## Descripci√≥n General\n",
    "\n",
    "Este notebook documenta las soluciones implementadas para analizar un dataset de aproximadamente 398MB de tweets relacionados con las protestas de agricultores en India (2021). Se resuelven 3 problemas, cada uno con 2 enfoques: optimizaci√≥n de tiempo y optimizaci√≥n de memoria.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "- **Archivo**: `farmers-protest-tweets-2021-2-4.json`\n",
    "- **Tama√±o**: ~389MB\n",
    "- **Formato**: JSONL (JSON Lines) - cada l√≠nea es un objeto JSON independiente\n",
    "- **Estructura**: Basada en Twitter API v1 data dictionary\n",
    "\n",
    "### Campos Relevantes Utilizados:\n",
    "- `date`: Fecha del tweet (ISO 8601 format)\n",
    "- `user.username`: Nombre de usuario del autor\n",
    "- `content`: Contenido del tweet (texto con emojis)\n",
    "- `mentionedUsers`: Lista de usuarios mencionados (@username)\n",
    "\n",
    "## Supuestos y Consideraciones\n",
    "\n",
    "1. **Formato de Datos**: Asumimos que el archivo es JSONL con un tweet por l√≠nea\n",
    "2. **Encoding**: UTF-8 para soportar emojis y caracteres especiales\n",
    "3. **Fechas**: Extraemos solo la fecha (sin hora) para Q1\n",
    "4. **Emojis**: Utilizamos regex Unicode para capturar todos los rangos de emojis est√°ndar\n",
    "5. **Menciones**: Usamos el campo `mentionedUsers` en lugar de parsear el contenido\n",
    "6. **Datos Faltantes**: Manejamos casos donde campos pueden ser `null` o no existir\n",
    "\n",
    "## Estrategias de Optimizaci√≥n\n",
    "\n",
    "### Time-Optimized (q*_time.py)\n",
    "- **Objetivo**: Minimizar tiempo de ejecuci√≥n\n",
    "- **T√©cnicas**: \n",
    "  - Carga de datos en memoria\n",
    "  - Uso de `Counter` para agregaciones O(1)\n",
    "  - Estructuras de datos eficientes (dict, defaultdict)\n",
    "  - Una sola pasada por el archivo cuando es posible\n",
    "\n",
    "### Memory-Optimized (q*_memory.py)\n",
    "- **Objetivo**: Minimizar uso de memoria\n",
    "- **T√©cnicas**:\n",
    "  - Procesamiento en streaming (line by line)\n",
    "  - Uso de dict b√°sico en lugar de Counter\n",
    "  - M√∫ltiples pasadas cuando es necesario para reducir datos en memoria\n",
    "  - Liberaci√≥n temprana de datos innecesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Librer√≠as importadas correctamente\n",
      "‚úì Archivo de datos: ../farmers-protest-tweets-2021-2-4.json\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n e Importaci√≥n de Librer√≠as\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from q1_time import q1_time\n",
    "from q1_memory import q1_memory\n",
    "from q2_time import q2_time\n",
    "from q2_memory import q2_memory\n",
    "from q3_time import q3_time\n",
    "from q3_memory import q3_memory\n",
    "\n",
    "\n",
    "file_path = \"../farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas correctamente\")\n",
    "print(f\"‚úì Archivo de datos: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1: Top 10 Fechas con M√°s Tweets\n",
    "\n",
    "**Objetivo**: Encontrar las 10 fechas con mayor cantidad de tweets y el usuario con m√°s publicaciones en cada fecha.\n",
    "\n",
    "### Enfoque Time-Optimized (q1_time.py)\n",
    "- **Estrategia**: Una sola pasada por el archivo\n",
    "- **Estructuras**: `Counter` para fechas, `defaultdict(Counter)` para usuarios por fecha\n",
    "- **Complejidad**: O(n) tiempo, O(n) espacio en el peor caso\n",
    "\n",
    "### Enfoque Memory-Optimized (q1_memory.py)\n",
    "- **Estrategia**: Dos pasadas por el archivo\n",
    "- **Primera pasada**: Contar tweets por fecha, identificar top 10\n",
    "- **Segunda pasada**: Contar usuarios solo para las 10 fechas relevantes\n",
    "- **Complejidad**: O(2n) tiempo, O(d + 10*u) espacio (d=fechas √∫nicas, u=usuarios promedio por fecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 TIME-OPTIMIZED\n",
      "============================================================\n",
      "Tiempo de ejecuci√≥n: 9.9888 segundos\n",
      "Top 10 Fechas con M√°s Tweets:\n",
      "\n",
      " 1. 2021-02-12 - Usuario: @RanbirS00614606\n",
      " 2. 2021-02-13 - Usuario: @MaanDee08215437\n",
      " 3. 2021-02-17 - Usuario: @RaaJVinderkaur\n",
      " 4. 2021-02-16 - Usuario: @jot__b\n",
      " 5. 2021-02-14 - Usuario: @rebelpacifist\n",
      " 6. 2021-02-18 - Usuario: @neetuanjle_nitu\n",
      " 7. 2021-02-15 - Usuario: @jot__b\n",
      " 8. 2021-02-20 - Usuario: @MangalJ23056160\n",
      " 9. 2021-02-23 - Usuario: @Surrypuria\n",
      "10. 2021-02-19 - Usuario: @Preetm91\n"
     ]
    }
   ],
   "source": [
    "# Q1 Time-Optimized: Ejecuci√≥n y Medici√≥n\n",
    "\n",
    "print(\"Q1 TIME-OPTIMIZED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "result_q1_time = q1_time(file_path)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n: {elapsed_time:.4f} segundos\")\n",
    "print(f\"Top 10 Fechas con M√°s Tweets:\\n\")\n",
    "\n",
    "for idx, (date, username) in enumerate(result_q1_time, 1):\n",
    "    print(f\"{idx:2d}. {date} - Usuario: @{username}\")\n",
    "\n",
    "q1_time_result = result_q1_time\n",
    "q1_time_elapsed = elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 MEMORY-OPTIMIZED\n",
      "============================================================\n",
      "\n",
      "Tiempo de ejecuci√≥n: 16.9289 segundos\n",
      "\n",
      "üìä Top 10 Fechas con M√°s Tweets:\n",
      "\n",
      " 1. 2021-02-12 - Usuario: @RanbirS00614606\n",
      " 2. 2021-02-13 - Usuario: @MaanDee08215437\n",
      " 3. 2021-02-17 - Usuario: @RaaJVinderkaur\n",
      " 4. 2021-02-16 - Usuario: @jot__b\n",
      " 5. 2021-02-14 - Usuario: @rebelpacifist\n",
      " 6. 2021-02-18 - Usuario: @neetuanjle_nitu\n",
      " 7. 2021-02-15 - Usuario: @jot__b\n",
      " 8. 2021-02-20 - Usuario: @MangalJ23056160\n",
      " 9. 2021-02-23 - Usuario: @Surrypuria\n",
      "10. 2021-02-19 - Usuario: @Preetm91\n"
     ]
    }
   ],
   "source": [
    "# Q1 Memory-Optimized: Ejecuci√≥n y Medici√≥n\n",
    "\n",
    "print(\"Q1 MEMORY-OPTIMIZED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "result_q1_memory = q1_memory(file_path)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n: {elapsed_time:.4f} segundos\")\n",
    "print(f\"Top 10 Fechas con M√°s Tweets:\\n\")\n",
    "\n",
    "for idx, (date, username) in enumerate(result_q1_memory, 1):\n",
    "    print(f\"{idx:2d}. {date} - Usuario: @{username}\")\n",
    "\n",
    "\n",
    "q1_memory_result = result_q1_memory\n",
    "q1_memory_elapsed = elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificaci√≥n: Resultados id√©nticos = True\n",
      "Diferencia de tiempo: 6.9401 segundos\n"
     ]
    }
   ],
   "source": [
    "# Comparaci√≥n Q1\n",
    "\n",
    "print(f\"\\nVerificaci√≥n: Resultados id√©nticos = {result_q1_time == result_q1_memory}\")\n",
    "print(f\"Diferencia de tiempo: {abs(q1_time_elapsed - q1_memory_elapsed):.4f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis Q1: Profiling con memory_profiler\n",
    "\n",
    "Usamos `%memit` para medir el pico de memoria durante la ejecuci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midiendo memoria para q1_time...\n",
      "peak memory: 77.01 MiB, increment: 0.00 MiB\n",
      "\n",
      "Midiendo memoria para q1_memory...\n",
      "peak memory: 77.01 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "# Profiling de memoria para Q1\n",
    "\n",
    "print(\"Midiendo memoria para q1_time...\")\n",
    "%memit q1_time(file_path)\n",
    "\n",
    "print(\"\\nMidiendo memoria para q1_memory...\")\n",
    "%memit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q2: Top 10 Emojis M√°s Usados\n",
    "\n",
    "**Objetivo**: Encontrar los 10 emojis m√°s frecuentes en los tweets con su conteo.\n",
    "\n",
    "### Enfoque Time-Optimized (q2_time.py)\n",
    "- **Estrategia**: Usar `Counter` para agregaci√≥n r√°pida\n",
    "- **Extracci√≥n**: Regex Unicode compilado para encontrar todos los emojis\n",
    "- **Rangos Unicode cubiertos**: Emoticons, s√≠mbolos, banderas, pictogramas, etc.\n",
    "\n",
    "### Enfoque Memory-Optimized (q2_memory.py)\n",
    "- **Estrategia**: Usar dict b√°sico en lugar de Counter\n",
    "- **Mismo regex**: Pero con menor overhead de estructuras de datos\n",
    "- **Trade-off**: Sorting manual vs Counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2 TIME-OPTIMIZED\n",
      "============================================================\n",
      "Tiempo de ejecuci√≥n: 9.5493 segundos\n",
      "Top 10 Emojis M√°s Usados:\n",
      "\n",
      " 1. üôè - 7,286 veces\n",
      " 2. üòÇ - 3,072 veces\n",
      " 3. Ô∏è - 3,061 veces\n",
      " 4. üöú - 2,972 veces\n",
      " 5. ‚úä - 2,411 veces\n",
      " 6. üåæ - 2,363 veces\n",
      " 7. üáÆ - 2,096 veces\n",
      " 8. üá≥ - 2,094 veces\n",
      " 9. üèª - 2,080 veces\n",
      "10. ‚ù§ - 1,779 veces\n"
     ]
    }
   ],
   "source": [
    "# Q2 Time-Optimized: Ejecuci√≥n y Medici√≥n\n",
    "\n",
    "\n",
    "print(\"Q2 TIME-OPTIMIZED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "result_q2_time = q2_time(file_path)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n: {elapsed_time:.4f} segundos\")\n",
    "print(f\"Top 10 Emojis M√°s Usados:\\n\")\n",
    "\n",
    "for idx, (emoji, count) in enumerate(result_q2_time, 1):\n",
    "    print(f\"{idx:2d}. {emoji} - {count:,} veces\")\n",
    "\n",
    "q2_time_result = result_q2_time\n",
    "q2_time_elapsed = elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2 MEMORY-OPTIMIZED\n",
      "============================================================\n",
      "Tiempo de ejecuci√≥n: 9.0544 segundos\n",
      "Top 10 Emojis M√°s Usados:\n",
      "\n",
      " 1. üôè - 7,286 veces\n",
      " 2. üòÇ - 3,072 veces\n",
      " 3. Ô∏è - 3,061 veces\n",
      " 4. üöú - 2,972 veces\n",
      " 5. ‚úä - 2,411 veces\n",
      " 6. üåæ - 2,363 veces\n",
      " 7. üáÆ - 2,096 veces\n",
      " 8. üá≥ - 2,094 veces\n",
      " 9. üèª - 2,080 veces\n",
      "10. ‚ù§ - 1,779 veces\n"
     ]
    }
   ],
   "source": [
    "# Q2 Memory-Optimized: Ejecuci√≥n y Medici√≥n\n",
    "\n",
    "\n",
    "print(\"Q2 MEMORY-OPTIMIZED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "result_q2_memory = q2_memory(file_path)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n: {elapsed_time:.4f} segundos\")\n",
    "print(f\"Top 10 Emojis M√°s Usados:\\n\")\n",
    "\n",
    "for idx, (emoji, count) in enumerate(result_q2_memory, 1):\n",
    "    print(f\"{idx:2d}. {emoji} - {count:,} veces\")\n",
    "\n",
    "q2_memory_result = result_q2_memory\n",
    "q2_memory_elapsed = elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificaci√≥n: Resultados id√©nticos = True\n",
      "Diferencia de tiempo: 0.4949 segundos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Verificaci√≥n: Resultados id√©nticos = {result_q2_time == result_q2_memory}\")\n",
    "print(f\"Diferencia de tiempo: {abs(q2_time_elapsed - q2_memory_elapsed):.4f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midiendo memoria para q2_time...\n",
      "peak memory: 77.01 MiB, increment: 0.00 MiB\n",
      "\n",
      "Midiendo memoria para q2_memory...\n",
      "peak memory: 77.01 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "# Profiling de memoria para Q2\n",
    "\n",
    "print(\"Midiendo memoria para q2_time...\")\n",
    "%memit q2_time(file_path)\n",
    "\n",
    "print(\"\\nMidiendo memoria para q2_memory...\")\n",
    "%memit q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q3: Top 10 Usuarios M√°s Mencionados\n",
    "\n",
    "**Objetivo**: Encontrar los 10 usuarios m√°s influyentes por cantidad de menciones (@username).\n",
    "\n",
    "### Enfoque Time-Optimized (q3_time.py)\n",
    "- **Estrategia**: Usar `Counter` para conteo r√°pido\n",
    "- **Fuente de datos**: Campo `mentionedUsers` del JSON\n",
    "- **Ventaja**: Una sola pasada, O(1) para inserci√≥n/actualizaci√≥n\n",
    "\n",
    "### Enfoque Memory-Optimized (q3_memory.py)\n",
    "- **Estrategia**: Dict b√°sico con `.get()` para minimizar overhead\n",
    "- **Trade-off**: Sorting manual al final vs Counter.most_common()\n",
    "- **Ahorro**: Menos overhead de objeto Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 TIME-OPTIMIZED\n",
      "============================================================\n",
      "Tiempo de ejecuci√≥n: 7.9409 segundos\n",
      "Top 10 Usuarios M√°s Mencionados:\n",
      "\n",
      " 1. @narendramodi - 2,265 menciones\n",
      " 2. @Kisanektamorcha - 1,840 menciones\n",
      " 3. @RakeshTikaitBKU - 1,644 menciones\n",
      " 4. @PMOIndia - 1,427 menciones\n",
      " 5. @RahulGandhi - 1,146 menciones\n",
      " 6. @GretaThunberg - 1,048 menciones\n",
      " 7. @RaviSinghKA - 1,019 menciones\n",
      " 8. @rihanna - 986 menciones\n",
      " 9. @UNHumanRights - 962 menciones\n",
      "10. @meenaharris - 926 menciones\n"
     ]
    }
   ],
   "source": [
    "# Q3 Time-Optimized: Ejecuci√≥n y Medici√≥n\n",
    "\n",
    "print(\"Q3 TIME-OPTIMIZED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "result_q3_time = q3_time(file_path)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n: {elapsed_time:.4f} segundos\")\n",
    "print(f\"Top 10 Usuarios M√°s Mencionados:\\n\")\n",
    "\n",
    "for idx, (username, count) in enumerate(result_q3_time, 1):\n",
    "    print(f\"{idx:2d}. @{username} - {count:,} menciones\")\n",
    "\n",
    "q3_time_result = result_q3_time\n",
    "q3_time_elapsed = elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 MEMORY-OPTIMIZED\n",
      "============================================================\n",
      "Tiempo de ejecuci√≥n: 8.0370 segundos\n",
      "Top 10 Usuarios M√°s Mencionados:\n",
      "\n",
      " 1. @narendramodi - 2,265 menciones\n",
      " 2. @Kisanektamorcha - 1,840 menciones\n",
      " 3. @RakeshTikaitBKU - 1,644 menciones\n",
      " 4. @PMOIndia - 1,427 menciones\n",
      " 5. @RahulGandhi - 1,146 menciones\n",
      " 6. @GretaThunberg - 1,048 menciones\n",
      " 7. @RaviSinghKA - 1,019 menciones\n",
      " 8. @rihanna - 986 menciones\n",
      " 9. @UNHumanRights - 962 menciones\n",
      "10. @meenaharris - 926 menciones\n"
     ]
    }
   ],
   "source": [
    "# Q3 Memory-Optimized: Ejecuci√≥n y Medici√≥n\n",
    "\n",
    "print(\"Q3 MEMORY-OPTIMIZED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "result_q3_memory = q3_memory(file_path)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Tiempo de ejecuci√≥n: {elapsed_time:.4f} segundos\")\n",
    "print(f\"Top 10 Usuarios M√°s Mencionados:\\n\")\n",
    "\n",
    "for idx, (username, count) in enumerate(result_q3_memory, 1):\n",
    "    print(f\"{idx:2d}. @{username} - {count:,} menciones\")\n",
    "\n",
    "q3_memory_result = result_q3_memory\n",
    "q3_memory_elapsed = elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificaci√≥n: Resultados id√©nticos = True\n",
      "Diferencia de tiempo: 0.0960 segundos\n"
     ]
    }
   ],
   "source": [
    "# Comparaci√≥n Q3\n",
    "\n",
    "print(f\"Verificaci√≥n: Resultados id√©nticos = {result_q3_time == result_q3_memory}\")\n",
    "print(f\"Diferencia de tiempo: {abs(q3_time_elapsed - q3_memory_elapsed):.4f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midiendo memoria para q3_time...\n",
      "peak memory: 77.01 MiB, increment: 0.00 MiB\n",
      "\n",
      "Midiendo memoria para q3_memory...\n",
      "peak memory: 77.01 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "# Profiling de memoria para Q3\n",
    "\n",
    "print(\"Midiendo memoria para q3_time...\")\n",
    "%memit q3_time(file_path)\n",
    "\n",
    "print(\"\\nMidiendo memoria para q3_memory...\")\n",
    "%memit q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resumen Comparativo de Performance\n",
    "\n",
    "Esta tabla resume el rendimiento de cada implementaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPARACI√ìN DE TIEMPOS DE EJECUCI√ìN\n",
      "============================================================\n",
      "Pregunta          Versi√≥n  Tiempo (s)\n",
      "      Q1   Time-Optimized      9.9888\n",
      "      Q1 Memory-Optimized     16.9289\n",
      "      Q2   Time-Optimized      9.5493\n",
      "      Q2 Memory-Optimized      9.0544\n",
      "      Q3   Time-Optimized      7.9409\n",
      "      Q3 Memory-Optimized      8.0370\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Tabla comparativa de tiempos\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = {\n",
    "    'Pregunta': ['Q1', 'Q1', 'Q2', 'Q2', 'Q3', 'Q3'],\n",
    "    'Versi√≥n': ['Time-Optimized', 'Memory-Optimized', 'Time-Optimized', 'Memory-Optimized', 'Time-Optimized', 'Memory-Optimized'],\n",
    "    'Tiempo (s)': [\n",
    "        q1_time_elapsed, q1_memory_elapsed,\n",
    "        q2_time_elapsed, q2_memory_elapsed,\n",
    "        q3_time_elapsed, q3_memory_elapsed\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "df['Tiempo (s)'] = df['Tiempo (s)'].round(4)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARACI√ìN DE TIEMPOS DE EJECUCI√ìN\")\n",
    "print(\"=\" * 60)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oportunidades de Mejora\n",
    "\n",
    "### Q1: Top 10 Fechas\n",
    "**Mejoras Posibles:**\n",
    "1. **Procesamiento paralelo**: Dividir el archivo en chunks y procesar en m√∫ltiples threads/procesos\n",
    "2. **Uso de pandas**: Cargar datos con `pd.read_json(lines=True)` y usar operaciones vectorizadas\n",
    "3. **Bases de datos**: Para datasets mayores, usar SQLite o DuckDB para queries SQL eficientes\n",
    "4. **Optimizaci√≥n de memoria extrema**: Usar generators y yield para no mantener estructuras completas\n",
    "5. **Cach√© de parsing de fechas**: Cachear conversiones de fecha repetidas\n",
    "\n",
    "### Q2: Top 10 Emojis\n",
    "**Mejoras Posibles:**\n",
    "1. **Librer√≠a especializada**: Usar `emoji` library en lugar de regex custom\n",
    "2. **Compilaci√≥n JIT**: Usar PyPy o Numba para acelerar loops de procesamiento de texto\n",
    "3. **Lazy evaluation**: Usar generators para procesar emojis bajo demanda\n",
    "4. **Multiprocessing**: Dividir archivo y procesar chunks en paralelo\n",
    "5. **Optimizar regex**: Usar caracteres Unicode m√°s espec√≠ficos para reducir b√∫squedas\n",
    "\n",
    "### Q3: Top 10 Usuarios Mencionados\n",
    "**Mejoras Posibles:**\n",
    "1. **√çndice invertido**: Para consultas repetidas, mantener √≠ndice de menciones\n",
    "2. **Streaming con l√≠mite**: Mantener solo top-K en memoria (heap-based approach)\n",
    "3. **Procesamiento incremental**: Actualizar resultados en tiempo real con nuevos datos\n",
    "4. **Compresi√≥n**: Usar IDs num√©ricos en lugar de strings para usernames\n",
    "5. **Apache Spark/Dask**: Para escalabilidad a datasets multi-GB\n",
    "\n",
    "### Mejoras Generales\n",
    "1. **Formato de archivo**: Usar Parquet en lugar de JSON para lectura m√°s r√°pida\n",
    "2. **Monitoreo**: Agregar logging detallado para identificar cuellos de botella\n",
    "3. **Testing**: Agregar unit tests y property-based testing\n",
    "4. **Validaci√≥n**: Agregar validaci√≥n de datos de entrada y manejo robusto de errores\n",
    "5. **Configuraci√≥n**: Hacer configurable el tama√±o de chunks, n√∫mero de workers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "### Principales Hallazgos\n",
    "\n",
    "1. **Trade-offs Tiempo vs Memoria**: \n",
    "   - Las versiones time-optimized usan estructuras m√°s complejas (Counter, defaultdict) que son m√°s r√°pidas pero consumen m√°s memoria\n",
    "   - Las versiones memory-optimized usan dict b√°sicos y m√∫ltiples pasadas cuando es necesario\n",
    "\n",
    "2. **Patrones de Optimizaci√≥n**:\n",
    "   - **Q1**: Dos pasadas (memory) vs una pasada (time)\n",
    "   - **Q2 y Q3**: Mismo algoritmo, diferente estructura de datos\n",
    "\n",
    "3. **Escalabilidad**:\n",
    "   - Para datasets de cientos de MB, las soluciones actuales son adecuadas\n",
    "   - Para datasets de GB/TB, se necesitar√≠a procesamiento distribuido (Spark, Dask)\n",
    "\n",
    "4. **Calidad de C√≥digo**:\n",
    "   - C√≥digo limpio y modular en archivos separados\n",
    "   - Tipo hints para mejor mantenibilidad\n",
    "   - Manejo de casos edge (datos faltantes, None values)\n",
    "\n",
    "### Lecciones Aprendidas\n",
    "\n",
    "- El formato JSONL es eficiente para procesamiento streaming\n",
    "- Python collections (Counter, defaultdict) son muy √∫tiles para agregaciones\n",
    "- El profiling es esencial para identificar verdaderos cuellos de botella\n",
    "- No siempre existe un claro ganador: depende del contexto (hardware, tama√±o de datos, frecuencia de ejecuci√≥n)\n",
    "\n",
    "### Pr√≥ximos Pasos\n",
    "\n",
    "Si este an√°lisis se llevara a producci√≥n:\n",
    "1. Implementar logging y monitoreo\n",
    "2. Agregar tests unitarios e integraci√≥n\n",
    "3. Configurar CI/CD para validaci√≥n autom√°tica\n",
    "4. Considerar migraci√≥n a formato columnar (Parquet)\n",
    "5. Evaluar soluciones cloud (BigQuery, Redshift, Snowflake) para escalabilidad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
