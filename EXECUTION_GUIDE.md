# Gu√≠a de Ejecuci√≥n - Challenge Data Engineering

## Instalaci√≥n de Dependencias

```bash
cd challenge_data_ops_eng
pip install -r requirements.txt
```

## Estructura de Archivos

```
challenge_data_ops_eng/
‚îú‚îÄ‚îÄ farmers-protest-tweets-2021-2-4.json  # Dataset (389MB)
‚îú‚îÄ‚îÄ requirements.txt                       # Dependencias Python
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ q1_time.py                        # Q1 optimizado para tiempo
‚îÇ   ‚îú‚îÄ‚îÄ q1_memory.py                      # Q1 optimizado para memoria
‚îÇ   ‚îú‚îÄ‚îÄ q2_time.py                        # Q2 optimizado para tiempo
‚îÇ   ‚îú‚îÄ‚îÄ q2_memory.py                      # Q2 optimizado para memoria
‚îÇ   ‚îú‚îÄ‚îÄ q3_time.py                        # Q3 optimizado para tiempo
‚îÇ   ‚îú‚îÄ‚îÄ q3_memory.py                      # Q3 optimizado para memoria
‚îÇ   ‚îî‚îÄ‚îÄ challenge.ipynb                   # Notebook con an√°lisis completo
```

## Ejecuci√≥n del An√°lisis

### Opci√≥n 1: Jupyter Notebook (Recomendado)

```bash
cd challenge_data_ops_eng/src
jupyter notebook challenge.ipynb
```

El notebook incluye:
- Importaci√≥n de todas las funciones
- Ejecuci√≥n y medici√≥n de tiempo de cada funci√≥n
- Profiling de memoria con `memory_profiler`
- Comparaci√≥n de resultados
- An√°lisis detallado y conclusiones

### Opci√≥n 2: Usar las Funciones Directamente

```python
from q1_time import q1_time
from q1_memory import q1_memory

# Ejecutar Q1
file_path = "../farmers-protest-tweets-2021-2-4.json"
result = q1_time(file_path)
print(result)
```

## Resultados Esperados

### Q1: Top 10 Fechas con M√°s Tweets
Formato: `[(datetime.date, str), ...]`
```python
[(datetime.date(2021, 2, 12), "username1"), ...]
```

### Q2: Top 10 Emojis M√°s Usados
Formato: `[(str, int), ...]`
```python
[("üôè", 5000), ("‚ù§Ô∏è", 4500), ...]
```

### Q3: Top 10 Usuarios M√°s Mencionados
Formato: `[(str, int), ...]`
```python
[("narendramodi", 2000), ("RahulGandhi", 1500), ...]
```

## Profiling de Performance

### Medir Tiempo de Ejecuci√≥n

```python
import time

start = time.time()
result = q1_time(file_path)
elapsed = time.time() - start
print(f"Tiempo: {elapsed:.4f} segundos")
```

### Medir Memoria

```python
# En Jupyter Notebook
%load_ext memory_profiler
%memit q1_time(file_path)
```

```bash
# Desde l√≠nea de comandos
python -m memory_profiler script.py
```

## Notas T√©cnicas

### Estrategias de Optimizaci√≥n

**Time-Optimized:**
- Una sola pasada por el archivo
- Uso de Counter y defaultdict
- Mayor consumo de memoria
- Menor tiempo de ejecuci√≥n

**Memory-Optimized:**
- M√∫ltiples pasadas cuando es necesario
- Uso de dict b√°sico
- Menor consumo de memoria
- Mayor tiempo de ejecuci√≥n

### Manejo de Datos

- Encoding: UTF-8
- Formato: JSONL (una l√≠nea por tweet)
- Tama√±o: ~389MB
- Campos utilizados: `date`, `user.username`, `content`, `mentionedUsers`

## Troubleshooting

### Error: FileNotFoundError
Aseg√∫rate de que el archivo JSON est√© en la carpeta `challenge_data_ops_eng/`

### Error: Memory Error
Si tienes problemas de memoria, usa las versiones `*_memory.py`

### Jupyter Kernel Issues
```bash
python -m ipykernel install --user --name=challenge
```

## Pr√≥ximos Pasos

Para mejorar estas soluciones:
1. Implementar procesamiento paralelo (multiprocessing)
2. Usar formatos m√°s eficientes (Parquet)
3. Agregar tests unitarios
4. Implementar logging y monitoreo
5. Considerar soluciones cloud (BigQuery, Spark)
